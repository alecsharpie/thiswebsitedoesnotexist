{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ByBZ9MuX59fk",
        "outputId": "5297f0dc-76f3-4ce4-921c-47f03ff5c446"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Nov 27 06:37:19 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  A100-SXM4-40GB      Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   23C    P0    43W / 400W |      0MiB / 40536MiB |      0%      Default |\n",
            "|                               |                      |             Disabled |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets transformers evaluate huggingface_hub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1MhHANW8lpvs",
        "outputId": "998e423a-4996-4e61-daf1-cc8eb674d581"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (2.7.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.24.0)\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.3.0-py3-none-any.whl (72 kB)\n",
            "\u001b[K     |████████████████████████████████| 72 kB 1.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: huggingface_hub in /usr/local/lib/python3.7/dist-packages (0.11.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.14)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.13.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (3.1.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.11.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface_hub) (4.1.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface_hub) (3.8.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.8.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (22.1.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.1.1)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.25.11)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2022.9.24)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: evaluate\n",
            "Successfully installed evaluate-0.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DziOQwednaec",
        "outputId": "16d3223e-b90c-4ef7-e341-99a8c1da04da"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To login, `huggingface_hub` now requires a token generated from https://huggingface.co/settings/tokens .\n",
            "    \n",
            "Token: \n",
            "Add token as git credential? (Y/n) n\n",
            "Token is valid.\n",
            "Your token has been saved to /root/.huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset"
      ],
      "metadata": {
        "id": "BXk4S9oTllQ6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QuZ5lomLkuL5",
        "outputId": "54ed086c-5415-4a34-c614-f9b36934e434"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Using custom data configuration bigcode--the-stack-a0e96fa31d53c718\n"
          ]
        }
      ],
      "source": [
        "# dataset streaming (will only download the data as needed)\n",
        "ds = load_dataset(\"bigcode/the-stack\", data_dir=\"data/dockerfile\", streaming=True, split=\"train\")\n",
        "# for sample in iter(ds): print(sample[\"content\"])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for sample in iter(ds): print(sample[\"content\"])"
      ],
      "metadata": {
        "id": "HorAlvauui8I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "checkpoint = \"Salesforce/codegen-350M-multi\" # 2B\n",
        "base_model = AutoModelForCausalLM.from_pretrained(checkpoint)\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu' \n",
        "\n",
        "# model = AutoModelForMaskedLM.from_pretrained(\"distilbert-base-uncased\")\n",
        "base_model.train().to(device)\n",
        "\n",
        "# maybe try sequence length of 1024\n"
      ],
      "metadata": {
        "id": "jM9FrUyTMoON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# text = \"\"\"function setup() {\n",
        "#   createCanvas(400, 400);\n",
        "# }\n",
        "\n",
        "# function draw() {\"\"\"\n",
        "\n",
        "\n",
        "text = \"\"\"\n",
        "<!DOCTYPE html>\n",
        "<html lang=\"en\">\n",
        "    <head>\n",
        "        <meta charset=\"UTF-8\" />\n",
        "        <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n",
        "\n",
        "        <link rel=\"stylesheet\" href=\"styles.css\" />\n",
        "        <title>Frogs</title>\n",
        "    </head>\n",
        "    <body>\"\"\"\n",
        "\n",
        "#         <header>\n",
        "#             <h1>>Header</h1>\n",
        "#         </header>\n",
        "\n",
        "#         <script src=\"Index.js\"></script>\n",
        "#     </body>\n",
        "# </html>\n",
        "# \"\"\"\n",
        "\n",
        "# text = \"\"\"\n",
        "# Create a circle on a canvas\n",
        "# \"\"\"\n",
        "\n",
        "batch = tokenizer(text, return_tensors=\"pt\")\n",
        "\n",
        "batch = {k: v.to(device) for k, v in batch.items()}\n",
        "\n",
        "completion = base_model.generate(**batch, max_new_tokens = 512)\n",
        "\n",
        "print(tokenizer.decode(completion[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GeqDvYqqfhCl",
        "outputId": "e3ab1edc-c1fe-4522-8765-6f530096c8e1"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "<!DOCTYPE html>\n",
            "<html lang=\"en\">\n",
            "    <head>\n",
            "        <meta charset=\"UTF-8\" />\n",
            "        <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n",
            "\n",
            "        <link rel=\"stylesheet\" href=\"styles.css\" />\n",
            "        <title>Frogs</title>\n",
            "    </head>\n",
            "    <body>\n",
            "        <div id=\"container\">\n",
            "            <div id=\"content\">\n",
            "                <div id=\"main\">\n",
            "                    <h1>Frogs</h1>\n",
            "                </div>\n",
            "            </div>\n",
            "        </div>\n",
            "    </body>\n",
            "</html>\n",
            "`\n",
            "\n",
            "const testHTML = `\n",
            "<!DOCTYPE html>\n",
            "<html lang=\"en\">\n",
            "    <head>\n",
            "        <meta charset=\"UTF-8\" />\n",
            "        <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n",
            "\n",
            "        <link rel=\"stylesheet\" href=\"styles.css\" />\n",
            "        <title>Frogs</title>\n",
            "    </head>\n",
            "    <body>\n",
            "        <div id=\"container\">\n",
            "            <div id=\"content\">\n",
            "                <div id=\"main\">\n",
            "                    <h1>Frogs</h1>\n",
            "                </div>\n",
            "            </div>\n",
            "        </div>\n",
            "    </body>\n",
            "</html>\n",
            "`\n",
            "\n",
            "func TestRender(t *testing.T) {\n",
            "\tt.Parallel()\n",
            "\n",
            "\tvar (\n",
            "\t\terr error\n",
            "\t\tout string\n",
            "\t)\n",
            "\n",
            "\t// Render the HTML\n",
            "\tout, err = Render(testHTML)\n",
            "\tif err!= nil {\n",
            "\t\tt.Fatal(err)\n",
            "\t}\n",
            "\n",
            "\t// Check the output\n",
            "\tif out!= testHTML {\n",
            "\t\tt.Errorf(\"Expected %q, got %q\", testHTML, out)\n",
            "\t}\n",
            "}\n",
            "\n",
            "func TestRenderWithContext(t *testing.T) {\n",
            "\tt.Parallel()\n",
            "\n",
            "\tvar (\n",
            "\t\terr error\n",
            "\t\tout string\n",
            "\t)\n",
            "\n",
            "\t// Render the HTML\n",
            "\tout, err = RenderWithContext(testHTML, \"\")\n",
            "\tif err!= nil {\n",
            "\t\tt.Fatal(err)\n",
            "\t}\n",
            "\n",
            "\t// Check the output\n",
            "\tif out!= testHTML {\n",
            "\t\tt.Errorf(\"Expected %q, got %q\", testHTML, out)\n",
            "\t}\n",
            "}\n",
            "\n",
            "func TestRenderWithContextAndContext(t *testing.T) {\n",
            "\tt.Parallel()\n",
            "\n",
            "\tvar (\n",
            "\t\terr error\n",
            "\t\tout string\n",
            "\t)\n",
            "\n",
            "\t// Render the HTML\n",
            "\tout, err = RenderWithContextAnd\n",
            "CPU times: user 17.6 s, sys: 13.9 ms, total: 17.6 s\n",
            "Wall time: 17.6 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "id": "aW12Ji4hen9w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine tune the model"
      ],
      "metadata": {
        "id": "dwMZ2E-TAE90"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhMuTqNnereM",
        "outputId": "f5c06f51-01f5-4a5c-dbf6-ffd84d59c984"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "checkpoint = \"Salesforce/codegen-350M-multi\" # 2B\n",
        "model = AutoModelForCausalLM.from_pretrained(checkpoint)\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu' \n",
        "\n",
        "model.train().to(device)\n",
        "\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "tokenizer.add_special_tokens({'pad_token': '<|pad|>', \n",
        "                              'eos_token':'<|endoftext|>',  \n",
        "                              'bos_token':'<|startoftext|>'})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKF7vtbWFjiQ",
        "outputId": "d6d3a225-3171-4139-da6c-d0a4ffcb8ce0"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Am8BB8rKL05b"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pytorch Native way"
      ],
      "metadata": {
        "id": "INyaB7FAL2QW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data.distributed import Dataset\n",
        "from datasets import load_dataset\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "seed, buffer_size = 42, 24\n",
        "\n",
        "ds = load_dataset(\"bigcode/the-stack\", data_dir=\"data/css\", streaming=True, split=\"train\")\n",
        "\n",
        "dataset = ds.map(lambda examples: tokenizer(examples['content'], return_tensors=\"pt\", padding='max_length', truncation=True, max_length=512)) #truncation = True, padding = True))\n",
        "\n",
        "# dataset = dataset.map(lambda examples: examples['input_ids'][0, -1]) #examples.update({'label_ids': }\n",
        "\n",
        "dataset = dataset.map(\n",
        "    lambda x: {\"label_ids\": x['input_ids'][0, -1]}\n",
        ")\n",
        "\n",
        "# dataset = dataset.map(\n",
        "#     lambda x: {\"input_ids\": x['input_ids'][:, 0:-1]}\n",
        "# )\n",
        "\n",
        "dataset = dataset.map(\n",
        "    lambda x: {\"input_ids\": x['input_ids'].reshape(-1)}\n",
        ")\n",
        "\n",
        "dataset = dataset.map(\n",
        "    lambda x: {\"attention_mask\": x['attention_mask'].reshape(-1)}\n",
        ")\n",
        "\n",
        "# dataset = dataset.map(\n",
        "#     lambda x: {\"input_ids\": x['input_ids'][0]}\n",
        "# )\n",
        "\n",
        "# dataset = dataset.map(\n",
        "#     lambda x: {\"attention_mask\": x['attention_mask'][0]}\n",
        "# )\n",
        "\n",
        "to_exclude = ['content', 'avg_line_length', 'max_line_length', 'alphanum_fraction', 'licenses', 'repository_name', 'path', 'size', 'lang', 'label_ids'] # 'input_ids', 'attention_mask', 'label_ids'\n",
        "\n",
        "dataset = dataset.remove_columns(to_exclude)\n",
        "\n",
        "# dataset = dataset.map(\n",
        "#     lambda x: {\"input_ids\": pad_sequence(x['input_ids'].tolist(), batch_first = True)}\n",
        "# )\n",
        "\n",
        "dataset = dataset.shuffle(seed, buffer_size=buffer_size)\n",
        "\n",
        "dataset = dataset.with_format(\"torch\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7tuTKjNgXxq",
        "outputId": "5418a6ae-ef75-433c-86d2-17d12194e215"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Using custom data configuration bigcode--the-stack-543172d89edd5e39\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import AutoModelForMaskedLM, #DataCollatorForLanguageModeling\n",
        "from tqdm import tqdm\n",
        "\n",
        "train_dataloader = DataLoader(dataset, batch_size=10)"
      ],
      "metadata": {
        "id": "GCXPxrQGAYyG"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for i, _ in zip(dataset, [1, 2, 3]):\n",
        "#   print(i.keys())"
      ],
      "metadata": {
        "id": "l2Gf6FJTBjUx"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ['content', 'avg_line_length', 'max_line_length', 'alphanum_fraction', 'licenses', 'repository_name', 'path', 'size', 'lang', 'input_ids', 'attention_mask', 'label_ids']"
      ],
      "metadata": {
        "id": "fGlS83YooGrc"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for i, _ in zip(train_dataloader, [1, 2, 3]):\n",
        "#   print(i)"
      ],
      "metadata": {
        "id": "ycTQbshMEo6b"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import get_scheduler, get_cosine_schedule_with_warmup\n",
        "\n",
        "optimizer = torch.optim.AdamW(params=model.parameters(), lr=1e-7)\n",
        "\n",
        "\n",
        "num_epochs = 90\n",
        "steps_per_epoch = 5\n",
        "\n",
        "\n",
        "num_training_steps = num_epochs * steps_per_epoch\n",
        "\n",
        "lr_scheduler = get_scheduler(\n",
        "    name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps\n",
        ")\n",
        "\n",
        "cosine_lr_scheduler = get_cosine_schedule_with_warmup(\n",
        "    optimizer = optimizer, num_warmup_steps = 150, num_training_steps = num_training_steps\n",
        ")"
      ],
      "metadata": {
        "id": "sMHxdoalAl3h"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in train_dataloader:\n",
        "  print(batch.items())\n",
        "  break"
      ],
      "metadata": {
        "id": "9Dd8NEGHlKoP"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epoch_history = []\n",
        "loss_history = []\n",
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    dataset.set_epoch(epoch)\n",
        "\n",
        "    epoch_history.append(epoch)\n",
        "\n",
        "    for i, batch in enumerate(tqdm(train_dataloader, total=steps_per_epoch)):\n",
        "        if i == steps_per_epoch:\n",
        "            break\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        outputs = model(**batch)\n",
        "        loss = outputs[0]\n",
        "        loss.mean().backward()\n",
        "\n",
        "        loss_history.append(loss.mean())\n",
        "\n",
        "        optimizer.step()\n",
        "        cosine_lr_scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "        if i % 10 == 0:\n",
        "            print(f\" loss: {loss.mean()}\")\n",
        "            "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfW4gRdo8BuP",
        "outputId": "a46bf5cb-2f76-4d94-afc7-c8b3a11108ff"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 1/5 [00:03<00:12,  3.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " loss: 18.076702117919922\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:06<00:00,  1.40s/it]\n",
            " 20%|██        | 1/5 [00:02<00:10,  2.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " loss: 16.793601989746094\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:06<00:00,  1.28s/it]\n",
            " 20%|██        | 1/5 [00:02<00:10,  2.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " loss: 14.570626258850098\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:06<00:00,  1.26s/it]\n",
            " 20%|██        | 1/5 [00:02<00:09,  2.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " loss: 18.63474464416504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:06<00:00,  1.27s/it]\n",
            " 20%|██        | 1/5 [00:02<00:09,  2.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " loss: 14.548398971557617\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:07<00:00,  1.41s/it]\n",
            " 20%|██        | 1/5 [00:03<00:12,  3.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " loss: 16.583656311035156\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:07<00:00,  1.50s/it]\n",
            " 20%|██        | 1/5 [00:03<00:12,  3.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " loss: 13.159344673156738\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:07<00:00,  1.55s/it]\n",
            " 20%|██        | 1/5 [00:04<00:16,  4.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " loss: 17.687538146972656\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:08<00:00,  1.62s/it]\n",
            " 20%|██        | 1/5 [00:02<00:09,  2.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " loss: 14.491167068481445\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:06<00:00,  1.20s/it]\n",
            " 20%|██        | 1/5 [00:03<00:13,  3.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " loss: 14.070979118347168\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:07<00:00,  1.50s/it]\n",
            " 20%|██        | 1/5 [00:03<00:15,  3.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " loss: 17.097578048706055\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:07<00:00,  1.56s/it]\n",
            " 20%|██        | 1/5 [00:02<00:10,  2.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " loss: 11.910438537597656\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:06<00:00,  1.29s/it]\n",
            " 20%|██        | 1/5 [00:03<00:13,  3.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " loss: 16.715364456176758\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:08<00:00,  1.63s/it]\n",
            " 20%|██        | 1/5 [00:03<00:13,  3.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " loss: 14.84394359588623\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:07<00:00,  1.43s/it]\n",
            " 20%|██        | 1/5 [00:03<00:12,  3.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " loss: 12.295144081115723\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:07<00:00,  1.50s/it]\n",
            " 20%|██        | 1/5 [00:03<00:13,  3.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " loss: 16.115503311157227\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:07<00:00,  1.48s/it]\n",
            " 20%|██        | 1/5 [00:02<00:11,  2.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " loss: 9.13477897644043\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:06<00:00,  1.30s/it]\n",
            " 20%|██        | 1/5 [00:02<00:10,  2.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " loss: 10.357149124145508\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:08<00:00,  1.72s/it]\n",
            " 20%|██        | 1/5 [00:03<00:13,  3.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " loss: 12.757976531982422\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:07<00:00,  1.44s/it]\n",
            " 20%|██        | 1/5 [00:02<00:10,  2.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " loss: 11.856660842895508\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:07<00:00,  1.41s/it]\n",
            " 20%|██        | 1/5 [00:05<00:20,  5.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " loss: 8.626347541809082\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:10<00:00,  2.02s/it]\n",
            " 20%|██        | 1/5 [00:06<00:24,  6.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " loss: 12.707552909851074\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:10<00:00,  2.01s/it]\n",
            " 20%|██        | 1/5 [00:04<00:18,  4.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " loss: 9.395090103149414\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:08<00:00,  1.74s/it]\n",
            " 20%|██        | 1/5 [00:04<00:19,  4.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " loss: 12.726781845092773\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:09<00:00,  1.82s/it]\n",
            " 20%|██        | 1/5 [00:02<00:08,  2.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " loss: 13.92534065246582\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:05<00:00,  1.18s/it]\n",
            " 20%|██        | 1/5 [00:02<00:10,  2.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " loss: 13.037986755371094\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:06<00:00,  1.38s/it]\n",
            " 20%|██        | 1/5 [00:04<00:16,  4.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " loss: 9.96101188659668\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:08<00:00,  1.63s/it]\n",
            " 20%|██        | 1/5 [00:02<00:10,  2.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " loss: 9.30012321472168\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:06<00:00,  1.28s/it]\n",
            " 20%|██        | 1/5 [00:02<00:11,  2.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " loss: 10.834664344787598\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:06<00:00,  1.37s/it]\n",
            " 20%|██        | 1/5 [00:04<00:16,  4.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " loss: 10.036764144897461\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:08<00:00,  1.69s/it]\n",
            " 20%|██        | 1/5 [00:02<00:09,  2.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " loss: 8.201153755187988\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:06<00:00,  1.29s/it]\n",
            " 20%|██        | 1/5 [00:03<00:12,  3.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " loss: 10.124494552612305\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:07<00:00,  1.48s/it]\n",
            " 20%|██        | 1/5 [00:03<00:13,  3.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " loss: 7.352560043334961\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:08<00:00,  1.63s/it]\n",
            " 20%|██        | 1/5 [00:02<00:10,  2.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " loss: 8.057169914245605\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:06<00:00,  1.32s/it]\n",
            " 20%|██        | 1/5 [00:02<00:11,  2.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " loss: 6.930476188659668\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:06<00:00,  1.30s/it]\n",
            " 20%|██        | 1/5 [00:02<00:11,  2.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " loss: 7.178282737731934\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:06<00:00,  1.39s/it]\n",
            " 20%|██        | 1/5 [00:02<00:11,  2.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " loss: 3.6854302883148193\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:08<00:00,  1.62s/it]\n",
            " 20%|██        | 1/5 [00:03<00:14,  3.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " loss: 6.67251443862915\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:08<00:00,  1.65s/it]\n",
            " 20%|██        | 1/5 [00:02<00:09,  2.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " loss: 6.352305889129639\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:06<00:00,  1.22s/it]\n",
            " 20%|██        | 1/5 [00:02<00:09,  2.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " loss: 5.647571086883545\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:06<00:00,  1.27s/it]\n",
            " 20%|██        | 1/5 [00:02<00:10,  2.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " loss: 2.759073257446289\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:06<00:00,  1.27s/it]\n",
            " 20%|██        | 1/5 [00:02<00:08,  2.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " loss: 2.5127480030059814\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:06<00:00,  1.22s/it]\n",
            " 20%|██        | 1/5 [00:03<00:12,  3.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " loss: 4.016353607177734\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:07<00:00,  1.42s/it]\n",
            " 20%|██        | 1/5 [00:02<00:11,  2.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " loss: 1.985703706741333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:06<00:00,  1.39s/it]\n",
            " 20%|██        | 1/5 [00:02<00:11,  2.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " loss: -0.09356065839529037\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:06<00:00,  1.37s/it]\n",
            " 20%|██        | 1/5 [00:02<00:10,  2.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " loss: 0.9578332901000977\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:06<00:00,  1.34s/it]\n",
            " 20%|██        | 1/5 [00:03<00:14,  3.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " loss: 1.512976884841919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:09<00:00,  1.84s/it]\n",
            " 20%|██        | 1/5 [00:02<00:10,  2.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " loss: 1.879026174545288\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:06<00:00,  1.24s/it]\n",
            " 20%|██        | 1/5 [00:02<00:10,  2.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " loss: 0.7418447136878967\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:06<00:00,  1.27s/it]\n",
            " 20%|██        | 1/5 [00:03<00:12,  3.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " loss: 1.3609910011291504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:07<00:00,  1.52s/it]\n",
            " 20%|██        | 1/5 [00:02<00:10,  2.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " loss: 0.5855627655982971\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:06<00:00,  1.25s/it]\n",
            " 20%|██        | 1/5 [00:02<00:11,  2.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " loss: -0.27331453561782837\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:06<00:00,  1.37s/it]\n",
            " 20%|██        | 1/5 [00:03<00:12,  3.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " loss: -0.5312369465827942\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:06<00:00,  1.38s/it]\n",
            " 20%|██        | 1/5 [00:02<00:11,  2.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " loss: -1.0744009017944336\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:06<00:00,  1.31s/it]\n",
            " 20%|██        | 1/5 [00:02<00:09,  2.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " loss: -0.526948094367981\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:07<00:00,  1.50s/it]\n",
            " 20%|██        | 1/5 [00:03<00:13,  3.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " loss: -1.0995848178863525\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:08<00:00,  1.64s/it]\n",
            " 20%|██        | 1/5 [00:02<00:10,  2.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " loss: -0.614962637424469\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:06<00:00,  1.35s/it]\n",
            " 20%|██        | 1/5 [00:03<00:13,  3.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " loss: -1.938238263130188\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:08<00:00,  1.63s/it]\n",
            " 20%|██        | 1/5 [00:02<00:11,  2.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " loss: -1.5418620109558105\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:07<00:00,  1.49s/it]\n",
            " 20%|██        | 1/5 [00:02<00:10,  2.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " loss: 0.2904965877532959\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:06<00:00,  1.26s/it]\n",
            " 20%|██        | 1/5 [00:12<00:49, 12.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " loss: -0.6279785633087158\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:16<00:00,  3.30s/it]\n",
            " 20%|██        | 1/5 [00:02<00:11,  2.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " loss: -3.5181691646575928\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:06<00:00,  1.30s/it]\n",
            " 20%|██        | 1/5 [00:02<00:11,  2.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " loss: -1.9865546226501465\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:07<00:00,  1.45s/it]\n",
            " 20%|██        | 1/5 [00:02<00:11,  2.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " loss: -2.629739761352539\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:08<00:00,  1.60s/it]\n",
            " 20%|██        | 1/5 [00:05<00:20,  5.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " loss: -2.3835861682891846\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:10<00:00,  2.05s/it]\n",
            " 20%|██        | 1/5 [00:05<00:20,  5.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " loss: -4.165061950683594\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:09<00:00,  1.91s/it]\n",
            " 20%|██        | 1/5 [00:05<00:21,  5.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " loss: -2.513122797012329\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:09<00:00,  1.88s/it]\n",
            " 20%|██        | 1/5 [00:03<00:14,  3.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " loss: -2.2499566078186035\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:08<00:00,  1.63s/it]\n",
            " 20%|██        | 1/5 [00:02<00:11,  2.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " loss: -2.728827714920044\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:06<00:00,  1.38s/it]\n",
            " 20%|██        | 1/5 [00:05<00:21,  5.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " loss: -3.4130847454071045\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:09<00:00,  2.00s/it]\n",
            " 20%|██        | 1/5 [00:02<00:10,  2.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " loss: -4.687435626983643\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:06<00:00,  1.26s/it]\n",
            " 20%|██        | 1/5 [00:05<00:20,  5.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " loss: -2.715751886367798\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:08<00:00,  1.76s/it]\n",
            " 20%|██        | 1/5 [00:05<00:22,  5.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " loss: -3.7461302280426025\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:09<00:00,  1.86s/it]\n",
            " 20%|██        | 1/5 [00:05<00:20,  5.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " loss: -5.068767547607422\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:11<00:00,  2.31s/it]\n",
            " 20%|██        | 1/5 [00:02<00:09,  2.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " loss: -2.9949655532836914\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:06<00:00,  1.36s/it]\n",
            " 20%|██        | 1/5 [00:10<00:43, 10.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " loss: -3.8275153636932373\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:14<00:00,  2.94s/it]\n",
            " 20%|██        | 1/5 [00:05<00:20,  5.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " loss: -2.0233309268951416\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:08<00:00,  1.78s/it]\n",
            " 20%|██        | 1/5 [00:04<00:19,  4.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " loss: -3.208757162094116\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:08<00:00,  1.71s/it]\n",
            " 20%|██        | 1/5 [00:05<00:20,  5.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " loss: -3.597428798675537\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:09<00:00,  1.80s/it]\n",
            " 20%|██        | 1/5 [00:04<00:17,  4.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " loss: -3.573007583618164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:08<00:00,  1.73s/it]\n",
            " 20%|██        | 1/5 [00:05<00:21,  5.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " loss: -2.774691581726074\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:09<00:00,  1.88s/it]\n",
            " 20%|██        | 1/5 [00:05<00:22,  5.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " loss: -5.048397541046143\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:10<00:00,  2.17s/it]\n",
            " 20%|██        | 1/5 [00:03<00:13,  3.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " loss: -2.8831515312194824\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:08<00:00,  1.60s/it]\n",
            " 20%|██        | 1/5 [00:06<00:24,  6.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " loss: -5.181588172912598\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:10<00:00,  2.18s/it]\n",
            " 20%|██        | 1/5 [00:05<00:21,  5.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " loss: -3.0786566734313965\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:09<00:00,  1.80s/it]\n",
            " 20%|██        | 1/5 [00:02<00:10,  2.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " loss: -4.872005939483643\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:08<00:00,  1.73s/it]\n",
            " 20%|██        | 1/5 [00:05<00:22,  5.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " loss: -4.671323776245117\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:09<00:00,  1.88s/it]\n",
            " 20%|██        | 1/5 [00:05<00:22,  5.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " loss: -3.068155288696289\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:09<00:00,  1.99s/it]\n",
            " 20%|██        | 1/5 [00:05<00:22,  5.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " loss: -3.778449535369873\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:09<00:00,  1.92s/it]\n",
            " 20%|██        | 1/5 [00:04<00:19,  4.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " loss: -4.489591121673584\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:09<00:00,  1.82s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in train_dataloader:\n",
        "  print(batch.items())\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Y1a5RH3HPQy",
        "outputId": "a8636863-0dff-4616-e4e3-1a0da4185860"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_items([('input_ids', tensor([[15211,  6624, 12982,  ...,    11,   201,   198],\n",
            "        [15211,     0,   198,  ...,     4, 27422, 37424],\n",
            "        [   31, 13199,  7972,  ..., 50295, 50295, 50295],\n",
            "        ...,\n",
            "        [  171,   119,   123,  ..., 50284, 17015,    25],\n",
            "        [15211, 10097,   438,  ...,    13,    17, 17428],\n",
            "        [    3, 13200,    12,  ...,    26,   198,     3]])), ('attention_mask', tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
            "        [1, 1, 1,  ..., 1, 1, 1],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [1, 1, 1,  ..., 1, 1, 1],\n",
            "        [1, 1, 1,  ..., 1, 1, 1],\n",
            "        [1, 1, 1,  ..., 1, 1, 1]]))])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_history = [float(loss.cpu().detach().numpy()) for loss in loss_history]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "Eg5oCMpo4GE8",
        "outputId": "a6b69a08-a162-4ff9-80db-965ec96d16ac"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-131-02ce2e62cd67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloss_history\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-131-02ce2e62cd67>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloss_history\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'cpu'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(loss_history);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "JcKPlokG3JMz",
        "outputId": "c8f757af-1bde-48cd-dfe2-56adef8631dc"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install guesslang"
      ],
      "metadata": {
        "id": "MIBKmKJGQols"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from guesslang import Guess\n",
        "\n",
        "\n",
        "guess = Guess()\n",
        "\n",
        "name = guess.language_name(\"\"\"\n",
        "var fontWeight = /^(bold|700|800|900|normal|400|600|300|200|100|80|50|40|30|20|10|8|4|2|1)$/i;\n",
        "\n",
        "function getFontWeight(font) {\n",
        "  var i, prop, value;\n",
        "  if (!font) {\n",
        "    return;\n",
        "  }\n",
        "  for (i = 0; i < font.weight.length; i++) {\n",
        "    prop = font.weight[i];\n",
        "    value = '' + prop;\n",
        "    if (fontWeight.test(value)) {\n",
        "      return prop;\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "\"\"\")\n",
        "\n",
        "print(name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhVuoQ8IQpue",
        "outputId": "86eff063-1771-4d57-dd05-988475068eb2"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "JavaScript\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "text = \"\"\"\n",
        "#container {\n",
        "  padding: 10px;\n",
        "}\n",
        "\n",
        "h1 {\n",
        "\"\"\"\n",
        "\n",
        "# text = \"\"\n",
        "\n",
        "# text = \"\"\"\n",
        "# Create a circle on a canvas\n",
        "# \"\"\"\n",
        "\n",
        "\n",
        "batch = tokenizer(text, return_tensors=\"pt\")\n",
        "\n",
        "batch = {k: v.to(device) for k, v in batch.items()}\n",
        "\n",
        "completion = model.generate(**batch, max_new_tokens = 512)\n",
        "\n",
        "print(tokenizer.decode(completion[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ouWu53UxHsc4",
        "outputId": "dd34460b-e5aa-4cfd-a306-668c7686eaa0"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "#container {\n",
            "  padding: 10px;\n",
            "}\n",
            "\n",
            "h1 {\n",
            "  font-size: 100%;\n",
            "  line-height: 130%;\n",
            "  font-weight: 400;\n",
            "  font-style: italic;\n",
            "  text-transform: uppercase;\n",
            "}\n",
            "\n",
            ".ace_editor {\n",
            "  display: inline-block;\n",
            "  margin: 0px;\n",
            "  padding: 0px;\n",
            "  border: 1px solid #ccc;\n",
            "  border-radius: 2px;\n",
            "  position: absolute;\n",
            "  top: 0px;\n",
            "  left: 0px;\n",
            "  padding: 4px 8px;\n",
            "  background: #fff;\n",
            "}\n",
            "\n",
            ".ace_editor.ace_cursor.ace_overwrite_tag {\n",
            "  text-decoration: underline;\n",
            "}\n",
            "\n",
            ".ace_editor.ace_marker-layer.ace_selection {\n",
            "  background: #00ff00;\n",
            "  color: #666;\n",
            "}\n",
            "\n",
            ".ace_editor.ace_marker-layer.ace_step {\n",
            "  background: #00ff00;\n",
            "  padding: 0 4px;\n",
            "}\n",
            "\n",
            ".ace_editor.ace_marker-layer.ace_bracket {\n",
            "  margin: -1px 0 0 -1px;\n",
            "  border: 1px solid #ccc;\n",
            "  padding: 1px 8px;\n",
            "}\n",
            "\n",
            ".ace_editor.ace_marker-layer.ace_active_line {\n",
            "  background: #00ff00;\n",
            "  opacity: 0.5;\n",
            "}\n",
            "\n",
            ".ace_editor.ace_gutter_active_line {\n",
            "  background-color: #eee;\n",
            "  opacity: 0.5;\n",
            "  cursor: pointer;\n",
            "  text-shadow: 1px 1px 1px #000;\n",
            "  border-radius: 2px;\n",
            "}\n",
            "\n",
            ".ace_editor.ace_marker-layer.ace_selected_word {\n",
            "  border: 1px solid #ccc;\n",
            "  background: #00ff00;\n",
            "  opacity: 0.5;\n",
            "}\n",
            "\n",
            ".ace_editor.ace_invisible {\n",
            "  color: #666;\n",
            "  font-style: italic;\n",
            "}\n",
            "\n",
            ".ace_editor.ace_keyword,\n",
            ".ace_editor.ace_variable {\n",
            "  color: #666;\n",
            "  font-weight\n",
            "CPU times: user 17.6 s, sys: 10.5 ms, total: 17.6 s\n",
            "Wall time: 17.6 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save"
      ],
      "metadata": {
        "id": "iln9PRLGJCLo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZszirOJJEVe",
        "outputId": "84658a5d-4608-4fc5-cbae-e092c56c9527"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# os.makedirs(\"css_model\")\n",
        "\n",
        "model.save_pretrained(\"css_model\")\n",
        "\n",
        "model.push_to_hub(\"codegen_css\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdLeL0ArJBZf",
        "outputId": "87eb7295-8f0a-4bfb-bb09-3507259ed81a"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/alecsharpie/codegen_css/commit/a71cc47c6635199d01b20f1d7ecde43c7908450b', commit_message='Upload CodeGenForCausalLM', commit_description='', oid='a71cc47c6635199d01b20f1d7ecde43c7908450b', pr_url=None, pr_revision=None, pr_num=None)"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate"
      ],
      "metadata": {
        "id": "osMVyEMGHtV5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import evaluate\n",
        "\n",
        "metric = evaluate.load(\"accuracy\")"
      ],
      "metadata": {
        "id": "rHcRMbbf0m_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://huggingface.co/docs/transformers/perplexity"
      ],
      "metadata": {
        "id": "gricv84aHp7k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return metric.compute(predictions=predictions, references=labels)"
      ],
      "metadata": {
        "id": "85Ro_FKO0o-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "\n",
        "metric = evaluate.load(\"accuracy\")\n",
        "model.eval()\n",
        "\n",
        "for batch in eval_dataloader:\n",
        "    batch = {k: v.to(device) for k, v in batch.items()}\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**batch)\n",
        "\n",
        "    logits = outputs.logits\n",
        "    predictions = torch.argmax(logits, dim=-1)\n",
        "    metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
        "\n",
        "metric.compute()"
      ],
      "metadata": {
        "id": "tSl9GMgr0o7Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RGKcvrPR0o3k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J9DPcp9S0oyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hArSytKT0oNR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for k, v in batch.items():\n",
        "  print(v.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnSuLNXgr1oq",
        "outputId": "7711c42f-4c0e-426a-84fc-e89be4c20e33"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 512])\n",
            "torch.Size([2, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Easy huggingface trainer way"
      ],
      "metadata": {
        "id": "qo2YN1twLusX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data.distributed import Dataset\n",
        "from datasets import load_dataset\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "seed, buffer_size = 42, 512\n",
        "\n",
        "ds = load_dataset(\"bigcode/the-stack\", data_dir=\"data/css\", streaming=True, split=\"train\")\n",
        "\n",
        "dataset = ds.map(lambda examples: tokenizer(examples['content'], return_tensors=\"pt\", padding='max_length', truncation=True, max_length=512)) #truncation = True, padding = True))\n",
        "\n",
        "# dataset = dataset.map(lambda examples: examples['input_ids'][0, -1]) #examples.update({'label_ids': }\n",
        "\n",
        "dataset = dataset.map(\n",
        "    lambda x: {\"label_ids\": x['input_ids'][0, -1]}\n",
        ")\n",
        "\n",
        "dataset = dataset.map(\n",
        "    lambda x: {\"input_ids\": x['input_ids'][:, 0:-1]}\n",
        ")\n",
        "\n",
        "# dataset = dataset.map(\n",
        "#     lambda x: {\"input_ids\": pad_sequence(x['input_ids'].tolist(), batch_first = True)}\n",
        "# )\n",
        "\n",
        "dataset = dataset.shuffle(seed, buffer_size=buffer_size)\n",
        "\n",
        "dataset = dataset.with_format(\"torch\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "moTGLv03Mst5",
        "outputId": "13d902e6-273b-4484-bc3b-067f80ae4404"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Using custom data configuration bigcode--the-stack-543172d89edd5e39\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "training_args = TrainingArguments(output_dir=\"test_trainer\", max_steps = 3, per_device_train_batch_size = 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plomO_PO8DTP",
        "outputId": "6592911e-7262-470f-fcc4-ed58fdb17893"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=dataset,\n",
        "    # eval_dataset=small_eval_dataset,\n",
        "    # compute_metrics=compute_metrics,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1JcmWtCl8DQ_",
        "outputId": "a50478f7-2c01-413d-8b5f-dabc16f98ddd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "max_steps is given, it will override any value given in num_train_epochs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 516
        },
        "id": "qGGSpzDi8DOh",
        "outputId": "c0318368-6e2a-4381-89b2-b630d4eab0cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 6\n",
            "  Num Epochs = 9223372036854775807\n",
            "  Instantaneous batch size per device = 2\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 2\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 3\n",
            "  Number of trainable parameters = 356712448\n",
            "The following columns in the training set don't have a corresponding argument in `CodeGenForCausalLM.forward` and have been ignored: lang, max_line_length, path, licenses, repository_name, avg_line_length, size, alphanum_fraction, content. If lang, max_line_length, path, licenses, repository_name, avg_line_length, size, alphanum_fraction, content are not expected by `CodeGenForCausalLM.forward`,  you can safely ignore this message.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-3435b262f1ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1503\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1504\u001b[0m             \u001b[0mtrial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1505\u001b[0;31m             \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1506\u001b[0m         )\n\u001b[1;32m   1507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1747\u001b[0m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1749\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1751\u001b[0m                 if (\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2507\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2508\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2510\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_gpu\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   2538\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2539\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2540\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2541\u001b[0m         \u001b[0;31m# Save past state if it exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2542\u001b[0m         \u001b[0;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/codegen/modeling_codegen.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/codegen/modeling_codegen.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    582\u001b[0m                     \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m                     \u001b[0muse_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 584\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    585\u001b[0m                 )\n\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/codegen/modeling_codegen.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    308\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m             \u001b[0muse_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m         )\n\u001b[1;32m    312\u001b[0m         \u001b[0mattn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattn_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# output_attn: a, present, (attentions)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/codegen/modeling_codegen.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, layer_past, head_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;31m# compute self-attention: V x Softmax(QK^T)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m         \u001b[0mattn_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mattn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_merge_heads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_attention_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/codegen/modeling_codegen.py\u001b[0m in \u001b[0;36m_attn\u001b[0;34m(self, query, key, value, attention_mask, head_mask)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mattention_mask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0;31m# Apply the attention mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m             \u001b[0mattn_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattn_weights\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0mattn_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (511) must match the size of tensor b (512) at non-singleton dimension 3"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids,past_key_values,attention_mask,token_type_ids,position_ids,head_mask,inputs_embeds,labels,use_cache,output_attentions,output_hidden_states,return_dict,label,label_ids,labels."
      ],
      "metadata": {
        "id": "hVoXQYk08DL5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, _ in zip(dataset, [1, 2, 3]):\n",
        "  print(i['input_ids'].tolist(), i['label_ids'])"
      ],
      "metadata": {
        "id": "lsjugEGf8DJn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rZxeAHcEzcSS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}